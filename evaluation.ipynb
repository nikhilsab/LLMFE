{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c53fd971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error,roc_auc_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from optimization_utils import is_categorical\n",
    "from caafe.preprocessing import make_datasets_numeric\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from caafe import data\n",
    "import heapq\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from tabpfn import TabPFNRegressor, TabPFNClassifier\n",
    "\n",
    "######\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec24f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance-scale : 0.934 +- 0.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/nikhilsa/miniconda3/envs/tab_ml/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/grads/nikhilsa/miniconda3/envs/tab_ml/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/grads/nikhilsa/miniconda3/envs/tab_ml/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/grads/nikhilsa/miniconda3/envs/tab_ml/lib/python3.11/site-packages/caafe/preprocessing.py:44: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return column.map(mapping).fillna(-1).astype(int)\n",
      "/home/grads/nikhilsa/miniconda3/envs/tab_ml/lib/python3.11/site-packages/caafe/preprocessing.py:44: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return column.map(mapping).fillna(-1).astype(int)\n",
      "/home/grads/nikhilsa/miniconda3/envs/tab_ml/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crab : -2.277 +- 0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/nikhilsa/miniconda3/envs/tab_ml/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from caafe import data\n",
    "import pandas as pd\n",
    "import torch\n",
    "import heapq\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "import statistics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Load data observations\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "pb_name = ['breast-w', 'crab']\n",
    "\n",
    "feature_fn = []\n",
    "seed = 42\n",
    "for problem_name in pb_name:\n",
    "    is_regression =False\n",
    "    if problem_name in ['forest-fires', 'housing', 'insurance', 'bike', 'wine', 'crab']:\n",
    "        is_regression = True\n",
    "    llm= \"gpt3.5\"\n",
    "    # Load data observations\n",
    "    file_name = f\"./data/{problem_name}.csv\"\n",
    "\n",
    "    df = pd.read_csv(file_name)\n",
    "    target_attr = df.columns[-1]\n",
    "    \n",
    "    is_cat = [is_categorical(df.iloc[:, i]) for i in range(df.shape[1])][:-1]\n",
    "    attribute_names = df.columns[:-1].tolist()\n",
    "\n",
    "    X = df.convert_dtypes()\n",
    "    y = df[target_attr].to_numpy()\n",
    "    label_list = np.unique(y).tolist()\n",
    "\n",
    "    X = X.drop(target_attr, axis=1)\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'string':\n",
    "            X[col] = label_encoder.fit_transform(X[col])\n",
    "    if is_regression == False:\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    else:\n",
    "        skf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    i = 1\n",
    "    max_score_avg = []\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        test_outputs_all = []\n",
    "        max_score = -1000000.0\n",
    "        label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "        X_train_fold, X_test_fold = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train_fold, y_test_fold = y[train_idx], y[test_idx]\n",
    "        directory = f'./logs/{problem_name}_{llm}_split_{i}/samples'\n",
    "\n",
    "        data = []\n",
    "\n",
    "        for idx, filename in enumerate(os.listdir(directory)):\n",
    "            if filename.endswith(\".json\"):\n",
    "                filepath = os.path.join(directory, filename)\n",
    "                with open(filepath, \"r\") as f:\n",
    "                    if idx == 1:\n",
    "                        data.append(max_score)                        \n",
    "                    data.append(json.load(f)['score'])\n",
    "\n",
    "        data = [max_score if v is None else v for v in data]\n",
    "        best_k = heapq.nlargest(3, range(len(data)), key=data.__getitem__)\n",
    "        for filename in best_k:\n",
    "            if filename == 1:\n",
    "                continue\n",
    "            filepath = f'{directory}/samples_{filename}.json'\n",
    "            with open(filepath, \"r\") as f:\n",
    "                feature_fn = json.load(f)['function']\n",
    "            exec(feature_fn)\n",
    "            try:\n",
    "                df_train_modified = modify_features(X_train_fold)\n",
    "                for col in df_train_modified.columns:\n",
    "                    if df_train_modified[col].dtype == 'string':\n",
    "                        df_train_modified[col] = label_encoder.fit_transform(df_train_modified[col])\n",
    "                \n",
    "                df_test_modified = modify_features(X_test_fold)\n",
    "                for col in df_test_modified.columns: \n",
    "                    if df_test_modified[col].dtype == 'string':\n",
    "                        df_test_modified[col] = label_encoder.fit_transform(df_test_modified[col])\n",
    "                df_train_new, df_test_new = make_datasets_numeric(df_train_modified, df_test_modified, target_attr)\n",
    "\n",
    "                X_train = torch.tensor(df_train_new.to_numpy())\n",
    "                X_test = torch.tensor(df_test_new.to_numpy())\n",
    "                \n",
    "                if is_regression == True:\n",
    "                    model = xgb.XGBRegressor(random_state=42)\n",
    "                    y_train = y_train_fold\n",
    "                    y_test = y_test_fold\n",
    "                    X_train_new = X_train\n",
    "                    X_test_new = X_test\n",
    "                else:\n",
    "                    model = xgb.XGBClassifier(random_state=42)\n",
    "                    label_encoder = preprocessing.LabelEncoder()\n",
    "                    y_train = label_encoder.fit_transform(y_train_fold)\n",
    "                    y_test = label_encoder.fit_transform(y_test_fold)\n",
    "                    X_train_new = X_train\n",
    "                    X_test_new = X_test\n",
    "\n",
    "                # After fitting the model:\n",
    "                model.fit(torch.nan_to_num(X_train_new), y_train)\n",
    "\n",
    "                # Get predictions from the model.\n",
    "                if is_regression:\n",
    "                    # For regression, predict target values directly.\n",
    "                    y_pred = model.predict(torch.nan_to_num(X_test_new))\n",
    "                else:\n",
    "                    # For classification, get class probabilities.\n",
    "                    y_pred = model.predict(torch.nan_to_num(X_test_new))\n",
    "                    \n",
    "                test_outputs_all.append(y_pred)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if len(test_outputs_all) > 0:\n",
    "            test_outputs_all = np.stack(test_outputs_all, axis=0)  # Shape: (n_candidates, n_samples, n_classes) for classification\n",
    "\n",
    "        if is_regression:\n",
    "            # For regression, average predictions and compute negative RMSE.\n",
    "            pred = np.mean(test_outputs_all, axis=0)\n",
    "            score = -mean_squared_error(y_test, pred, squared=False)\n",
    "        else:\n",
    "            # For classification, average the probability estimates.\n",
    "            # Convert averaged probabilities to predicted class labels.\n",
    "            from scipy import stats\n",
    "            pred = stats.mode(test_outputs_all, axis=0)[0]\n",
    "\n",
    "            score = accuracy_score(y_test, pred)\n",
    "\n",
    "        max_score_avg.append(score)\n",
    "        i +=1\n",
    "    mean_val = sum(max_score_avg)/ len(max_score_avg)\n",
    "    mean_val\n",
    "    std_dev = statistics.stdev(max_score_avg)\n",
    "    print(f'{problem_name} : {mean_val:.3f} +- {std_dev:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74785833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tab_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
